{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Vision Encoder:** ViT\n",
    "\n",
    "### **Text Decoder:** GPT-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-09-12T13:48:17.686709Z",
     "iopub.status.busy": "2024-09-12T13:48:17.686289Z",
     "iopub.status.idle": "2024-09-12T13:48:18.836244Z",
     "shell.execute_reply": "2024-09-12T13:48:18.835210Z",
     "shell.execute_reply.started": "2024-09-12T13:48:17.686670Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T13:48:18.838965Z",
     "iopub.status.busy": "2024-09-12T13:48:18.838427Z",
     "iopub.status.idle": "2024-09-12T13:48:18.926084Z",
     "shell.execute_reply": "2024-09-12T13:48:18.925002Z",
     "shell.execute_reply.started": "2024-09-12T13:48:18.838928Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('/kaggle/input/chest-xrays-indiana-university/indiana_projections.csv')\n",
    "df1 = pd.read_csv('/kaggle/input/indiana-pro-reports/indiana_PROreports.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T13:48:18.927681Z",
     "iopub.status.busy": "2024-09-12T13:48:18.927304Z",
     "iopub.status.idle": "2024-09-12T13:48:18.943810Z",
     "shell.execute_reply": "2024-09-12T13:48:18.942644Z",
     "shell.execute_reply.started": "2024-09-12T13:48:18.927648Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df2=df2[df2['projection'] == 'Frontal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T13:48:18.947226Z",
     "iopub.status.busy": "2024-09-12T13:48:18.946820Z",
     "iopub.status.idle": "2024-09-12T13:48:18.965870Z",
     "shell.execute_reply": "2024-09-12T13:48:18.964666Z",
     "shell.execute_reply.started": "2024-09-12T13:48:18.947192Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T13:48:18.967899Z",
     "iopub.status.busy": "2024-09-12T13:48:18.967568Z",
     "iopub.status.idle": "2024-09-12T13:48:39.478523Z",
     "shell.execute_reply": "2024-09-12T13:48:39.477497Z",
     "shell.execute_reply.started": "2024-09-12T13:48:18.967869Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    AutoFeatureExtractor, \n",
    "    AutoTokenizer, \n",
    "    VisionEncoderDecoderModel,\n",
    "    Seq2SeqTrainingArguments,\n",
    "    Seq2SeqTrainer, \n",
    "    default_data_collator,\n",
    ")\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from pathlib import Path\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T13:48:39.480287Z",
     "iopub.status.busy": "2024-09-12T13:48:39.479721Z",
     "iopub.status.idle": "2024-09-12T13:48:39.501099Z",
     "shell.execute_reply": "2024-09-12T13:48:39.499985Z",
     "shell.execute_reply.started": "2024-09-12T13:48:39.480259Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T13:48:39.503294Z",
     "iopub.status.busy": "2024-09-12T13:48:39.502897Z",
     "iopub.status.idle": "2024-09-12T13:48:44.110089Z",
     "shell.execute_reply": "2024-09-12T13:48:44.109120Z",
     "shell.execute_reply.started": "2024-09-12T13:48:39.503250Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "images_captions_df = pd.DataFrame({'imgs': [],\n",
    "                                    'captions': []})\n",
    "for i in range(len(df2)):\n",
    "    uid = df2.iloc[i]['uid']\n",
    "    image = df2.iloc[i]['filename']\n",
    "    index = df1.loc[df1['uid'] ==uid]\n",
    "    \n",
    "    if not index.empty:    \n",
    "        index = index.index[0]\n",
    "        caption = df1.iloc[index]['findings']\n",
    "        if type(caption) == float:\n",
    "         \n",
    "            continue \n",
    "        images_captions_df = pd.concat([images_captions_df, pd.DataFrame([{'imgs': image, 'captions': caption}])], ignore_index=True)\n",
    "images_captions_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T13:48:44.111823Z",
     "iopub.status.busy": "2024-09-12T13:48:44.111454Z",
     "iopub.status.idle": "2024-09-12T13:48:44.119789Z",
     "shell.execute_reply": "2024-09-12T13:48:44.118739Z",
     "shell.execute_reply.started": "2024-09-12T13:48:44.111793Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(images_captions_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T13:48:44.121652Z",
     "iopub.status.busy": "2024-09-12T13:48:44.121282Z",
     "iopub.status.idle": "2024-09-12T13:48:45.307072Z",
     "shell.execute_reply": "2024-09-12T13:48:45.306094Z",
     "shell.execute_reply.started": "2024-09-12T13:48:44.121624Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "encoder_checkpoint = \"google/vit-base-patch16-224-in21k\"\n",
    "decoder_checkpoint = \"gpt2\"\n",
    "\n",
    "feature_extractor = AutoFeatureExtractor.from_pretrained(encoder_checkpoint)\n",
    "tokenizer = AutoTokenizer.from_pretrained(decoder_checkpoint)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T13:48:45.311291Z",
     "iopub.status.busy": "2024-09-12T13:48:45.310981Z",
     "iopub.status.idle": "2024-09-12T13:48:45.325083Z",
     "shell.execute_reply": "2024-09-12T13:48:45.323411Z",
     "shell.execute_reply.started": "2024-09-12T13:48:45.311264Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "p = '/kaggle/input/chest-xrays-indiana-university/images/images_normalized/'\n",
    "images_captions_df['imgs'] = p+ images_captions_df['imgs']\n",
    "images_captions_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T13:48:45.326605Z",
     "iopub.status.busy": "2024-09-12T13:48:45.326219Z",
     "iopub.status.idle": "2024-09-12T13:48:45.552976Z",
     "shell.execute_reply": "2024-09-12T13:48:45.551818Z",
     "shell.execute_reply.started": "2024-09-12T13:48:45.326576Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# maximum length for the captions\n",
    "max_length = 384\n",
    "sample = images_captions_df.iloc[99]\n",
    "\n",
    "# sample image\n",
    "image = Image.open(sample['imgs']).convert('RGB')\n",
    "# sample caption\n",
    "caption = sample['captions']\n",
    "\n",
    "# apply feature extractor on the sample image\n",
    "inputs = feature_extractor(images=image, return_tensors='pt')\n",
    "# apply tokenizer\n",
    "outputs = tokenizer(\n",
    "            caption, \n",
    "            max_length=max_length, \n",
    "            truncation=True, \n",
    "            padding='max_length',\n",
    "            return_tensors='pt',\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T13:48:45.554711Z",
     "iopub.status.busy": "2024-09-12T13:48:45.554360Z",
     "iopub.status.idle": "2024-09-12T13:48:45.624148Z",
     "shell.execute_reply": "2024-09-12T13:48:45.623113Z",
     "shell.execute_reply.started": "2024-09-12T13:48:45.554683Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(f\"Inputs:\\n{inputs}\\nOutputs:\\n{outputs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T13:48:45.626144Z",
     "iopub.status.busy": "2024-09-12T13:48:45.625715Z",
     "iopub.status.idle": "2024-09-12T13:48:45.636883Z",
     "shell.execute_reply": "2024-09-12T13:48:45.635866Z",
     "shell.execute_reply.started": "2024-09-12T13:48:45.626104Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "\n",
    "class LoadDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.images = df['imgs'].values\n",
    "        self.captions = df['captions'].values\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # everything to return is stored inside this dict\n",
    "        inputs = dict()\n",
    "\n",
    "        # load the image and apply feature_extractor\n",
    "        image_path = str(self.images[idx])\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        image = feature_extractor(images=image, return_tensors='pt')\n",
    "\n",
    "        # load the caption and apply tokenizer\n",
    "        caption = self.captions[idx]\n",
    "        labels = tokenizer(\n",
    "            caption, \n",
    "            max_length=max_length, \n",
    "            truncation=True, \n",
    "            padding='max_length',\n",
    "            return_tensors='pt',\n",
    "        )['input_ids'][0]\n",
    "        \n",
    "        # store the inputs, labels, and image path in the dict we created\n",
    "        inputs['pixel_values'] = image['pixel_values'].squeeze()   \n",
    "        inputs['labels'] = labels\n",
    "        \n",
    "        return inputs\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T13:48:45.638430Z",
     "iopub.status.busy": "2024-09-12T13:48:45.638108Z",
     "iopub.status.idle": "2024-09-12T13:48:45.653499Z",
     "shell.execute_reply": "2024-09-12T13:48:45.652305Z",
     "shell.execute_reply.started": "2024-09-12T13:48:45.638402Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(images_captions_df, test_size=0.2, shuffle=True, random_state=42)\n",
    "\n",
    "train_ds = LoadDataset(train_df)\n",
    "test_ds = LoadDataset(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T13:48:45.655296Z",
     "iopub.status.busy": "2024-09-12T13:48:45.654947Z",
     "iopub.status.idle": "2024-09-12T13:48:45.855005Z",
     "shell.execute_reply": "2024-09-12T13:48:45.853570Z",
     "shell.execute_reply.started": "2024-09-12T13:48:45.655265Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T13:48:45.858315Z",
     "iopub.status.busy": "2024-09-12T13:48:45.857129Z",
     "iopub.status.idle": "2024-09-12T13:48:45.863484Z",
     "shell.execute_reply": "2024-09-12T13:48:45.862263Z",
     "shell.execute_reply.started": "2024-09-12T13:48:45.858252Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T13:48:45.865549Z",
     "iopub.status.busy": "2024-09-12T13:48:45.865048Z",
     "iopub.status.idle": "2024-09-12T13:48:45.900022Z",
     "shell.execute_reply": "2024-09-12T13:48:45.898669Z",
     "shell.execute_reply.started": "2024-09-12T13:48:45.865497Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T13:48:45.901819Z",
     "iopub.status.busy": "2024-09-12T13:48:45.901431Z",
     "iopub.status.idle": "2024-09-12T13:48:47.212395Z",
     "shell.execute_reply": "2024-09-12T13:48:47.211401Z",
     "shell.execute_reply.started": "2024-09-12T13:48:45.901784Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "I=cv2.imread(test_df['imgs'].iloc[0])\n",
    "plt.imshow(I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T13:48:47.214426Z",
     "iopub.status.busy": "2024-09-12T13:48:47.213861Z",
     "iopub.status.idle": "2024-09-12T13:48:47.221957Z",
     "shell.execute_reply": "2024-09-12T13:48:47.220869Z",
     "shell.execute_reply.started": "2024-09-12T13:48:47.214380Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "len(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T13:48:47.223495Z",
     "iopub.status.busy": "2024-09-12T13:48:47.223177Z",
     "iopub.status.idle": "2024-09-12T13:48:47.395011Z",
     "shell.execute_reply": "2024-09-12T13:48:47.393956Z",
     "shell.execute_reply.started": "2024-09-12T13:48:47.223447Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "out=test_ds[90]['labels']\n",
    "tokenizer.decode(out, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T13:48:47.396640Z",
     "iopub.status.busy": "2024-09-12T13:48:47.396255Z",
     "iopub.status.idle": "2024-09-12T13:48:47.536724Z",
     "shell.execute_reply": "2024-09-12T13:48:47.535616Z",
     "shell.execute_reply.started": "2024-09-12T13:48:47.396614Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "len(test_ds[90]['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T13:48:47.538486Z",
     "iopub.status.busy": "2024-09-12T13:48:47.538043Z",
     "iopub.status.idle": "2024-09-12T13:48:47.661866Z",
     "shell.execute_reply": "2024-09-12T13:48:47.660765Z",
     "shell.execute_reply.started": "2024-09-12T13:48:47.538409Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "next(iter(test_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T13:48:47.664113Z",
     "iopub.status.busy": "2024-09-12T13:48:47.663508Z",
     "iopub.status.idle": "2024-09-12T13:48:53.838534Z",
     "shell.execute_reply": "2024-09-12T13:48:53.837425Z",
     "shell.execute_reply.started": "2024-09-12T13:48:47.664072Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model = VisionEncoderDecoderModel.from_encoder_decoder_pretrained(\n",
    "    encoder_checkpoint, \n",
    "    decoder_checkpoint\n",
    ")\n",
    "model.config.decoder_start_token_id = tokenizer.bos_token_id\n",
    "model.config.pad_token_id = tokenizer.pad_token_id\n",
    "# model.config.vocab_size = model.config.decoder.vocab_size\n",
    "model.config.num_beams = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T13:48:53.840268Z",
     "iopub.status.busy": "2024-09-12T13:48:53.839950Z",
     "iopub.status.idle": "2024-09-12T13:48:55.602216Z",
     "shell.execute_reply": "2024-09-12T13:48:55.601120Z",
     "shell.execute_reply.started": "2024-09-12T13:48:53.840239Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "batch = next(iter(train_ds))\n",
    "\n",
    "model(pixel_values=batch['pixel_values'].unsqueeze(0), labels=batch['labels'].unsqueeze(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-20T08:24:38.674932Z",
     "iopub.status.busy": "2024-08-20T08:24:38.674648Z",
     "iopub.status.idle": "2024-08-20T08:24:38.678588Z",
     "shell.execute_reply": "2024-08-20T08:24:38.677764Z",
     "shell.execute_reply.started": "2024-08-20T08:24:38.674907Z"
    }
   },
   "source": [
    "## Training block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T13:48:55.604017Z",
     "iopub.status.busy": "2024-09-12T13:48:55.603613Z",
     "iopub.status.idle": "2024-09-12T13:48:56.111027Z",
     "shell.execute_reply": "2024-09-12T13:48:56.109909Z",
     "shell.execute_reply.started": "2024-09-12T13:48:55.603980Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"image-caption-generator\",  # name of the directory to store training outputs\n",
    "    evaluation_strategy=\"epoch\",           # evaluate after each epoch\n",
    "    per_device_train_batch_size=8,         # batch size during training\n",
    "    per_device_eval_batch_size=8,          # batch size during evaluation\n",
    "    learning_rate=5e-5,\n",
    "    weight_decay=0.01,                     # weight decay for AdamW optimizer\n",
    "    num_train_epochs=4,                    # number of epochs to train\n",
    "    save_strategy='epoch',                 # save checkpoints after each epoch\n",
    "    report_to='none',                      # prevents logging to wandb, mlflow...\n",
    "    gradient_accumulation_steps=4          # accumulate gradients over 4 steps\n",
    ")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model, \n",
    "    tokenizer=feature_extractor, \n",
    "    data_collator=default_data_collator,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=test_ds,\n",
    "    args=training_args,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T13:48:56.113245Z",
     "iopub.status.busy": "2024-09-12T13:48:56.112402Z",
     "iopub.status.idle": "2024-09-12T14:36:03.884511Z",
     "shell.execute_reply": "2024-09-12T14:36:03.883383Z",
     "shell.execute_reply.started": "2024-09-12T13:48:56.113206Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T14:36:03.886891Z",
     "iopub.status.busy": "2024-09-12T14:36:03.886013Z",
     "iopub.status.idle": "2024-09-12T14:36:05.631635Z",
     "shell.execute_reply": "2024-09-12T14:36:05.630621Z",
     "shell.execute_reply.started": "2024-09-12T14:36:03.886854Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "i=245\n",
    "inputs = test_ds[i]['pixel_values']\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "\n",
    "\n",
    "    # model prediction \n",
    "    out = model.generate(\n",
    "        inputs.unsqueeze(0).to('cuda'), # move inputs to GPU\n",
    "        num_beams=4, \n",
    "        max_length=max_length\n",
    "        )\n",
    "# convert token ids to string format\n",
    "print('DS:')\n",
    "print(tokenizer.decode(test_ds[i]['labels'],skip_special_tokens=True))\n",
    "print('GPT2:')\n",
    "decoded_out = tokenizer.decode(out[0], skip_special_tokens=True)\n",
    "\n",
    "print(decoded_out)\n",
    "plt.axis('off')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T14:36:05.643669Z",
     "iopub.status.busy": "2024-09-12T14:36:05.643090Z",
     "iopub.status.idle": "2024-09-12T14:36:07.244306Z",
     "shell.execute_reply": "2024-09-12T14:36:07.242935Z",
     "shell.execute_reply.started": "2024-09-12T14:36:05.643619Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "inputs = test_ds[43]['pixel_values']\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "\n",
    "\n",
    "    # model prediction \n",
    "    out = model.generate(\n",
    "        inputs.unsqueeze(0).to('cuda'), # move inputs to GPU\n",
    "        num_beams=4, \n",
    "        max_length=max_length\n",
    "        )\n",
    "# convert token ids to string format\n",
    "decoded_out = tokenizer.decode(out[0], skip_special_tokens=True)\n",
    "\n",
    "print(decoded_out)\n",
    "plt.axis('off')\n",
    "plt.imshow(torch.permute(inputs, (1, 2, 0)));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T14:36:07.250101Z",
     "iopub.status.busy": "2024-09-12T14:36:07.249413Z",
     "iopub.status.idle": "2024-09-12T14:36:08.830982Z",
     "shell.execute_reply": "2024-09-12T14:36:08.825111Z",
     "shell.execute_reply.started": "2024-09-12T14:36:07.250059Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "inputs = test_ds[89]['pixel_values']\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "   \n",
    "\n",
    "    # model prediction \n",
    "    out = model.generate(\n",
    "        inputs.unsqueeze(0).to('cuda'), # move inputs to GPU\n",
    "        num_beams=4, \n",
    "        max_length=max_length\n",
    "        )\n",
    "# convert token ids to string format\n",
    "decoded_out = tokenizer.decode(out[0], skip_special_tokens=True)\n",
    "\n",
    "print(decoded_out)\n",
    "plt.axis('off')\n",
    "plt.imshow(torch.permute(inputs, (1, 2, 0)));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T14:36:08.834715Z",
     "iopub.status.busy": "2024-09-12T14:36:08.833149Z",
     "iopub.status.idle": "2024-09-12T14:36:10.634465Z",
     "shell.execute_reply": "2024-09-12T14:36:10.633045Z",
     "shell.execute_reply.started": "2024-09-12T14:36:08.834653Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), '/kaggle/working/image-caption-generator/dense-caption-generator_pro.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T14:36:10.636584Z",
     "iopub.status.busy": "2024-09-12T14:36:10.636097Z",
     "iopub.status.idle": "2024-09-12T14:36:10.644902Z",
     "shell.execute_reply": "2024-09-12T14:36:10.643192Z",
     "shell.execute_reply.started": "2024-09-12T14:36:10.636544Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "len(test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-20T08:24:45.678194Z",
     "iopub.status.busy": "2024-08-20T08:24:45.677415Z",
     "iopub.status.idle": "2024-08-20T08:24:45.681755Z",
     "shell.execute_reply": "2024-08-20T08:24:45.680823Z",
     "shell.execute_reply.started": "2024-08-20T08:24:45.678165Z"
    }
   },
   "source": [
    "## Inference Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T14:36:10.681488Z",
     "iopub.status.busy": "2024-09-12T14:36:10.681085Z",
     "iopub.status.idle": "2024-09-12T14:36:18.067925Z",
     "shell.execute_reply": "2024-09-12T14:36:18.066710Z",
     "shell.execute_reply.started": "2024-09-12T14:36:10.681438Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T14:36:18.069919Z",
     "iopub.status.busy": "2024-09-12T14:36:18.069444Z",
     "iopub.status.idle": "2024-09-12T14:36:18.996104Z",
     "shell.execute_reply": "2024-09-12T14:36:18.995104Z",
     "shell.execute_reply.started": "2024-09-12T14:36:18.069879Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T14:36:18.997563Z",
     "iopub.status.busy": "2024-09-12T14:36:18.997210Z",
     "iopub.status.idle": "2024-09-12T14:36:20.442853Z",
     "shell.execute_reply": "2024-09-12T14:36:20.441370Z",
     "shell.execute_reply.started": "2024-09-12T14:36:18.997522Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "inputs = test_ds[56]['pixel_values']\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "   \n",
    "    # model prediction \n",
    "    out = model.generate(\n",
    "        inputs.unsqueeze(0).to('cuda'), # move inputs to GPU\n",
    "        num_beams=4, \n",
    "        max_length=max_length\n",
    "        )\n",
    "# convert token ids to string format\n",
    "decoded_out = tokenizer.decode(out[0], skip_special_tokens=True)\n",
    "\n",
    "print(decoded_out)\n",
    "plt.axis('off')\n",
    "plt.imshow(torch.permute(inputs, (1, 2, 0)));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T14:36:20.445449Z",
     "iopub.status.busy": "2024-09-12T14:36:20.444980Z",
     "iopub.status.idle": "2024-09-12T14:36:21.901660Z",
     "shell.execute_reply": "2024-09-12T14:36:21.900009Z",
     "shell.execute_reply.started": "2024-09-12T14:36:20.445404Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "inputs = test_ds[12]['pixel_values']\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    \n",
    "    # model prediction \n",
    "    out = model.generate(\n",
    "        inputs.unsqueeze(0).to('cuda'), # move inputs to GPU\n",
    "        num_beams=4, \n",
    "        max_length=max_length\n",
    "        )\n",
    "# convert token ids to string format\n",
    "decoded_out = tokenizer.decode(out[0], skip_special_tokens=True)\n",
    "\n",
    "print(decoded_out)\n",
    "plt.axis('off')\n",
    "plt.imshow(torch.permute(inputs, (1, 2, 0)));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T14:36:21.904672Z",
     "iopub.status.busy": "2024-09-12T14:36:21.904043Z",
     "iopub.status.idle": "2024-09-12T14:41:55.855901Z",
     "shell.execute_reply": "2024-09-12T14:41:55.854802Z",
     "shell.execute_reply.started": "2024-09-12T14:36:21.904610Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "DS=[]\n",
    "GPT=[]\n",
    "model.eval()\n",
    "for i in tqdm(range(0,250)):\n",
    "    inputs = test_ds[i]['pixel_values']\n",
    "    \n",
    "    with torch.no_grad():\n",
    "       \n",
    "\n",
    "        # model prediction \n",
    "        out = model.generate(\n",
    "            inputs.unsqueeze(0).to('cuda'), # move inputs to GPU\n",
    "            num_beams=4, \n",
    "            max_length=max_length\n",
    "            )\n",
    "    # convert token ids to string format\n",
    "\n",
    "    y_hat=tokenizer.decode(test_ds[i]['labels'],skip_special_tokens=True)\n",
    "    DS.append(y_hat)\n",
    "\n",
    "    y_pred=tokenizer.decode(out[0], skip_special_tokens=True)\n",
    "    GPT.append(y_pred)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T14:41:55.857723Z",
     "iopub.status.busy": "2024-09-12T14:41:55.857330Z",
     "iopub.status.idle": "2024-09-12T14:42:11.437651Z",
     "shell.execute_reply": "2024-09-12T14:42:11.436508Z",
     "shell.execute_reply.started": "2024-09-12T14:41:55.857687Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T14:42:11.439569Z",
     "iopub.status.busy": "2024-09-12T14:42:11.439198Z",
     "iopub.status.idle": "2024-09-12T14:42:11.573191Z",
     "shell.execute_reply": "2024-09-12T14:42:11.572007Z",
     "shell.execute_reply.started": "2024-09-12T14:42:11.439536Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T14:42:12.848725Z",
     "iopub.status.busy": "2024-09-12T14:42:12.848315Z",
     "iopub.status.idle": "2024-09-12T14:42:40.967472Z",
     "shell.execute_reply": "2024-09-12T14:42:40.966046Z",
     "shell.execute_reply.started": "2024-09-12T14:42:12.848687Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install transformers\n",
    "!pip install bert-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T14:42:40.970343Z",
     "iopub.status.busy": "2024-09-12T14:42:40.969366Z",
     "iopub.status.idle": "2024-09-12T14:42:41.018996Z",
     "shell.execute_reply": "2024-09-12T14:42:41.017920Z",
     "shell.execute_reply.started": "2024-09-12T14:42:40.970296Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "from bert_score import BERTScorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T14:42:41.020590Z",
     "iopub.status.busy": "2024-09-12T14:42:41.020270Z",
     "iopub.status.idle": "2024-09-12T14:42:45.519413Z",
     "shell.execute_reply": "2024-09-12T14:42:45.518381Z",
     "shell.execute_reply.started": "2024-09-12T14:42:41.020562Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "reference =DS\n",
    "candidate = GPT\n",
    "scorer = BERTScorer(model_type='bert-base-uncased')\n",
    "P, R, F1 = scorer.score(candidate, reference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T14:42:45.520955Z",
     "iopub.status.busy": "2024-09-12T14:42:45.520665Z",
     "iopub.status.idle": "2024-09-12T14:42:45.528091Z",
     "shell.execute_reply": "2024-09-12T14:42:45.527081Z",
     "shell.execute_reply.started": "2024-09-12T14:42:45.520928Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(f\"BERTScore Precision: {P.mean():.4f}, Recall: {R.mean():.4f}, F1: {F1.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 516716,
     "sourceId": 951996,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5195094,
     "sourceId": 8668852,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5181516,
     "sourceId": 8773615,
     "sourceType": "datasetVersion"
    },
    {
     "modelId": 72238,
     "modelInstanceId": 52680,
     "sourceId": 63182,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 73191,
     "modelInstanceId": 53386,
     "sourceId": 64020,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30733,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
